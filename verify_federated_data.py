"""
éªŒè¯è”é‚¦å­¦ä¹ æ•°æ®åˆ†å‰²çš„æ­£ç¡®æ€§
ç¡®ä¿æ¯ä¸ªå®¢æˆ·ç«¯ä½¿ç”¨ä¸åŒçš„æ•°æ®å­é›†
"""
import torch
import numpy as np
from dataset.cls_dataloader import train_dataloader
from dataset.federated_data_partition import create_federated_dataloaders
from collections import defaultdict

def verify_data_splitting():
    """éªŒè¯æ•°æ®åˆ†å‰²çš„æ­£ç¡®æ€§"""
    print("ğŸ” éªŒè¯è”é‚¦å­¦ä¹ æ•°æ®åˆ†å‰²")
    print("=" * 50)
    
    # åˆ›å»ºè”é‚¦æ•°æ®åˆ’åˆ†
    partitioner, client_dataloaders = create_federated_dataloaders(
        dataset=train_dataloader.dataset,
        num_clients=5,  # ä½¿ç”¨5ä¸ªå®¢æˆ·ç«¯è¿›è¡Œæµ‹è¯•
        alpha=0.5,
        batch_size=32,
        num_workers=0,  # é¿å…å¤šè¿›ç¨‹é—®é¢˜
        min_samples_per_client=50
    )
    
    print(f"âœ… åˆ›å»ºäº†{len(client_dataloaders)}ä¸ªå®¢æˆ·ç«¯æ•°æ®åŠ è½½å™¨")
    
    # æ”¶é›†æ¯ä¸ªå®¢æˆ·ç«¯çš„æ ·æœ¬ç´¢å¼•
    client_samples = defaultdict(set)
    client_labels = defaultdict(list)
    
    for client_id, dataloader in enumerate(client_dataloaders):
        print(f"\nå®¢æˆ·ç«¯ {client_id}:")
        batch_count = 0
        sample_count = 0
        
        for batch_idx, (data, targets) in enumerate(dataloader):
            batch_count += 1
            sample_count += len(targets)
            
            # æ”¶é›†æ ‡ç­¾åˆ†å¸ƒ
            client_labels[client_id].extend(targets.numpy().tolist())
            
            if batch_idx == 0:
                print(f"  ç¬¬ä¸€ä¸ªbatchå½¢çŠ¶: {data.shape}")
        
        print(f"  æ€»batchæ•°: {batch_count}")
        print(f"  æ€»æ ·æœ¬æ•°: {sample_count}")
        
        # åˆ†ææ ‡ç­¾åˆ†å¸ƒ
        unique_labels, counts = np.unique(client_labels[client_id], return_counts=True)
        top_labels = unique_labels[np.argsort(counts)[-5:]][::-1]  # å‰5ä¸ªæœ€å¸¸è§çš„æ ‡ç­¾
        print(f"  ä¸»è¦ç±»åˆ«: {top_labels.tolist()}")
        print(f"  ç±»åˆ«æ•°é‡: {len(unique_labels)}")
    
    # éªŒè¯æ•°æ®ä¸é‡å 
    print(f"\nğŸ” éªŒè¯æ•°æ®ä¸é‡å :")
    
    all_samples = set()
    overlap_found = False
    
    for client_id in range(len(client_dataloaders)):
        client_indices = set(partitioner.client_indices[client_id])
        
        # æ£€æŸ¥ä¸å·²æœ‰æ ·æœ¬çš„é‡å 
        overlap = all_samples.intersection(client_indices)
        if overlap:
            print(f"  âš ï¸  å®¢æˆ·ç«¯{client_id}ä¸ä¹‹å‰å®¢æˆ·ç«¯æœ‰{len(overlap)}ä¸ªé‡å æ ·æœ¬")
            overlap_found = True
        else:
            print(f"  âœ… å®¢æˆ·ç«¯{client_id}æ— é‡å æ ·æœ¬")
        
        all_samples.update(client_indices)
    
    if not overlap_found:
        print("  ğŸ‰ æ‰€æœ‰å®¢æˆ·ç«¯æ•°æ®å®Œå…¨ä¸é‡å ï¼")
    
    # éªŒè¯æ€»æ ·æœ¬æ•°
    total_original = len(train_dataloader.dataset)
    total_federated = len(all_samples)
    
    print(f"\nğŸ“Š æ ·æœ¬ç»Ÿè®¡:")
    print(f"  åŸå§‹æ•°æ®é›†æ ·æœ¬æ•°: {total_original}")
    print(f"  è”é‚¦åˆ†å‰²æ ·æœ¬æ•°: {total_federated}")
    print(f"  æ ·æœ¬è¦†ç›–ç‡: {total_federated/total_original*100:.1f}%")
    
    if total_federated == total_original:
        print("  âœ… æ ·æœ¬å®Œå…¨è¦†ç›–ï¼Œæ— ä¸¢å¤±ï¼")
    else:
        print(f"  âš ï¸  ä¸¢å¤±äº†{total_original - total_federated}ä¸ªæ ·æœ¬")
    
    return True

def test_training_data_flow():
    """æµ‹è¯•è®­ç»ƒæ—¶çš„æ•°æ®æµ"""
    print(f"\nğŸ”„ æµ‹è¯•è®­ç»ƒæ•°æ®æµ")
    print("=" * 50)
    
    # åˆ›å»ºè”é‚¦æ•°æ®åˆ’åˆ†
    partitioner, client_dataloaders = create_federated_dataloaders(
        dataset=train_dataloader.dataset,
        num_clients=3,
        alpha=0.5,
        batch_size=16,
        num_workers=0
    )
    
    print("æ¨¡æ‹Ÿä¸€ä¸ªepochçš„è®­ç»ƒ:")
    
    # æ¨¡æ‹Ÿé€‰æ‹©å®¢æˆ·ç«¯
    selected_client_ids = [0, 2]  # é€‰æ‹©å®¢æˆ·ç«¯0å’Œ2
    selected_dataloaders = [client_dataloaders[i] for i in selected_client_ids]
    
    print(f"é€‰æ‹©çš„å®¢æˆ·ç«¯: {selected_client_ids}")
    
    # åˆ›å»ºè¿­ä»£å™¨
    client_iterators = [iter(dataloader) for dataloader in selected_dataloaders]
    
    batch_idx = 0
    while True:
        active_clients = 0
        batch_data = {}
        
        for i, (client_id, iterator) in enumerate(zip(selected_client_ids, client_iterators)):
            try:
                data, targets = next(iterator)
                batch_data[client_id] = {
                    'data_shape': data.shape,
                    'labels': targets[:5].tolist()  # æ˜¾ç¤ºå‰5ä¸ªæ ‡ç­¾
                }
                active_clients += 1
            except StopIteration:
                batch_data[client_id] = {'status': 'finished'}
        
        if active_clients == 0:
            print(f"  æ‰€æœ‰å®¢æˆ·ç«¯æ•°æ®ç”¨å®Œï¼Œepochç»“æŸ")
            break
        
        if batch_idx < 3:  # åªæ˜¾ç¤ºå‰3ä¸ªbatch
            print(f"\n  Batch {batch_idx}:")
            for client_id, info in batch_data.items():
                if 'data_shape' in info:
                    print(f"    å®¢æˆ·ç«¯{client_id}: {info['data_shape']}, æ ‡ç­¾æ ·ä¾‹: {info['labels']}")
                else:
                    print(f"    å®¢æˆ·ç«¯{client_id}: {info['status']}")
        
        batch_idx += 1
        
        if batch_idx > 100:  # é˜²æ­¢æ— é™å¾ªç¯
            break
    
    print(f"  æ€»å…±å¤„ç†äº†{batch_idx}ä¸ªbatch")
    
    return True

def main():
    """è¿è¡Œæ‰€æœ‰éªŒè¯"""
    print("ğŸš€ è”é‚¦å­¦ä¹ æ•°æ®åˆ†å‰²éªŒè¯")
    print("=" * 60)
    
    tests = [
        ("æ•°æ®åˆ†å‰²æ­£ç¡®æ€§", verify_data_splitting),
        ("è®­ç»ƒæ•°æ®æµ", test_training_data_flow),
    ]
    
    for test_name, test_func in tests:
        try:
            print(f"\n{'='*20} {test_name} {'='*20}")
            result = test_func()
            print(f"âœ… {test_name} éªŒè¯é€šè¿‡")
        except Exception as e:
            print(f"âŒ {test_name} éªŒè¯å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    print(f"\nğŸ¯ æ€»ç»“:")
    print(f"å¦‚æœæ‰€æœ‰éªŒè¯éƒ½é€šè¿‡ï¼Œè¯´æ˜ï¼š")
    print(f"1. âœ… æ¯ä¸ªå®¢æˆ·ç«¯ä½¿ç”¨ä¸åŒçš„æ•°æ®å­é›†")
    print(f"2. âœ… æ•°æ®æ²¡æœ‰é‡å ")
    print(f"3. âœ… è®­ç»ƒæ—¶æ•°æ®æµæ­£ç¡®")
    print(f"4. âœ… çœŸæ­£å®ç°äº†è”é‚¦å­¦ä¹ çš„æ•°æ®éš”ç¦»")
    
    print(f"\nç°åœ¨çš„å®éªŒè®¾ç½®:")
    print(f"ğŸ“ åŸå®éªŒ: ResNet50(å®Œæ•´æ•°æ®) + MobileNetV2(å®Œæ•´æ•°æ®) + çŸ¥è¯†èåˆ")
    print(f"ğŸ“ æ–°å®éªŒ: ResNet50(å®Œæ•´æ•°æ®) + 50ä¸ªMobileNetV2(åˆ†å‰²æ•°æ®) + è”é‚¦å¹³å‡ + çŸ¥è¯†èåˆ")

if __name__ == "__main__":
    main()
