"""
å®éªŒä½“ç³»å®Œæ•´æ€§éªŒè¯è„šæœ¬
æ£€æŸ¥æ‰€æœ‰å¿…è¦çš„æ–‡ä»¶ã€ä¾èµ–å’Œé…ç½®æ˜¯å¦æ­£ç¡®
"""
import os
import sys
import importlib
import torch
from typing import List, Dict

def check_file_exists(file_path: str) -> bool:
    """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
    return os.path.exists(file_path)

def check_import(module_name: str) -> bool:
    """æ£€æŸ¥æ¨¡å—æ˜¯å¦èƒ½æ­£å¸¸å¯¼å…¥"""
    try:
        importlib.import_module(module_name)
        return True
    except ImportError:
        return False

def check_experiment_files() -> Dict[str, bool]:
    """æ£€æŸ¥å®éªŒè„šæœ¬æ–‡ä»¶"""
    files = {
        'run_baseline_mobilenetv2.py': 'åŸºçº¿å®éªŒè„šæœ¬',
        'run_res50_mbv2.py': 'MergeNetå®éªŒè„šæœ¬',
        'federated_batch_mergenet.py': 'è”é‚¦MergeNetå®éªŒè„šæœ¬',
        'pure_federated_learning.py': 'çº¯è”é‚¦å­¦ä¹ å®éªŒè„šæœ¬',
        'compare_results.py': 'ç»“æœå¯¹æ¯”åˆ†æè„šæœ¬',
        'auto_experiment_runner.py': 'è‡ªåŠ¨åŒ–å®éªŒè¿è¡Œå™¨',
        'demo_comparison.py': 'å®éªŒæ¼”ç¤ºè„šæœ¬',
        'run_experiments.sh': 'å¿«é€Ÿå¯åŠ¨è„šæœ¬'
    }
    
    results = {}
    print("ğŸ“ æ£€æŸ¥å®éªŒè„šæœ¬æ–‡ä»¶...")
    for file_path, description in files.items():
        exists = check_file_exists(file_path)
        status = "âœ…" if exists else "âŒ"
        print(f"  {status} {file_path} - {description}")
        results[file_path] = exists
    
    return results

def check_model_files() -> Dict[str, bool]:
    """æ£€æŸ¥æ¨¡å‹æ–‡ä»¶"""
    files = {
        'model/MobileNet_v2.py': 'MobileNetV2æ¨¡å‹',
        'model/ResNet.py': 'ResNetæ¨¡å‹',
        'model/param_attention.py': 'å‚æ•°æ³¨æ„åŠ›æ¨¡å—',
        'config/param_attention_config.yaml': 'MergeNeté…ç½®',
        'config/federated_mergenet_config.py': 'è”é‚¦å­¦ä¹ é…ç½®'
    }
    
    results = {}
    print("\nğŸ—ï¸ æ£€æŸ¥æ¨¡å‹å’Œé…ç½®æ–‡ä»¶...")
    for file_path, description in files.items():
        exists = check_file_exists(file_path)
        status = "âœ…" if exists else "âŒ"
        print(f"  {status} {file_path} - {description}")
        results[file_path] = exists
    
    return results

def check_dataset_files() -> Dict[str, bool]:
    """æ£€æŸ¥æ•°æ®é›†æ–‡ä»¶"""
    files = {
        'dataset/cls_dataloader.py': 'æ•°æ®åŠ è½½å™¨',
        'dataset/federated_data_partition.py': 'è”é‚¦æ•°æ®åˆ’åˆ†',
        'data/cifar-100-python.tar.gz': 'CIFAR-100æ•°æ®é›†'
    }
    
    results = {}
    print("\nğŸ“Š æ£€æŸ¥æ•°æ®é›†æ–‡ä»¶...")
    for file_path, description in files.items():
        exists = check_file_exists(file_path)
        status = "âœ…" if exists else "âŒ"
        print(f"  {status} {file_path} - {description}")
        results[file_path] = exists
    
    return results

def check_dependencies() -> Dict[str, bool]:
    """æ£€æŸ¥Pythonä¾èµ–"""
    dependencies = {
        'torch': 'PyTorch',
        'torchvision': 'TorchVision',
        'numpy': 'NumPy',
        'matplotlib': 'Matplotlib',
        'tqdm': 'TQDM',
        'yaml': 'PyYAML',
        'swanlab': 'SwanLab'
    }
    
    results = {}
    print("\nğŸ“¦ æ£€æŸ¥Pythonä¾èµ–...")
    for module, description in dependencies.items():
        can_import = check_import(module)
        status = "âœ…" if can_import else "âŒ"
        print(f"  {status} {module} - {description}")
        results[module] = can_import
    
    return results

def check_hardware() -> Dict[str, bool]:
    """æ£€æŸ¥ç¡¬ä»¶ç¯å¢ƒ"""
    results = {}
    print("\nğŸ–¥ï¸ æ£€æŸ¥ç¡¬ä»¶ç¯å¢ƒ...")
    
    # æ£€æŸ¥CUDA
    cuda_available = torch.cuda.is_available()
    status = "âœ…" if cuda_available else "âš ï¸"
    print(f"  {status} CUDAå¯ç”¨: {cuda_available}")
    results['cuda'] = cuda_available
    
    if cuda_available:
        device_count = torch.cuda.device_count()
        print(f"  ğŸ“± GPUæ•°é‡: {device_count}")
        results['gpu_count'] = device_count
        
        for i in range(device_count):
            gpu_name = torch.cuda.get_device_name(i)
            print(f"    GPU {i}: {gpu_name}")
    
    # æ£€æŸ¥å†…å­˜
    if hasattr(torch.cuda, 'get_device_properties'):
        if cuda_available:
            props = torch.cuda.get_device_properties(0)
            total_memory = props.total_memory / 1024**3  # GB
            print(f"  ğŸ’¾ GPUå†…å­˜: {total_memory:.1f} GB")
            results['gpu_memory'] = total_memory
    
    return results

def check_directories():
    """æ£€æŸ¥å’Œåˆ›å»ºå¿…è¦çš„ç›®å½•"""
    directories = ['logs', 'checkpoints', 'results']
    
    print("\nğŸ“ æ£€æŸ¥ç›®å½•ç»“æ„...")
    for dir_name in directories:
        if not os.path.exists(dir_name):
            os.makedirs(dir_name)
            print(f"  âœ… åˆ›å»ºç›®å½•: {dir_name}")
        else:
            print(f"  âœ… ç›®å½•å·²å­˜åœ¨: {dir_name}")

def run_simple_test():
    """è¿è¡Œç®€å•çš„åŠŸèƒ½æµ‹è¯•"""
    print("\nğŸ§ª è¿è¡Œç®€å•åŠŸèƒ½æµ‹è¯•...")
    
    try:
        # æµ‹è¯•æ¨¡å‹åŠ è½½
        from model.MobileNet_v2 import mobilenetv2
        model = mobilenetv2()
        param_count = sum(p.numel() for p in model.parameters())
        print(f"  âœ… MobileNetV2åŠ è½½æˆåŠŸï¼Œå‚æ•°é‡: {param_count:,}")
        
        # æµ‹è¯•æ•°æ®åŠ è½½
        from dataset.cls_dataloader import train_dataloader, test_dataloader
        print(f"  âœ… æ•°æ®åŠ è½½å™¨åˆ›å»ºæˆåŠŸ")
        print(f"    è®­ç»ƒé›†æ‰¹æ¬¡æ•°: {len(train_dataloader)}")
        print(f"    æµ‹è¯•é›†æ‰¹æ¬¡æ•°: {len(test_dataloader)}")
        
        # æµ‹è¯•è”é‚¦æ•°æ®åˆ’åˆ†
        from dataset.federated_data_partition import create_federated_dataloaders
        partitioner, client_loaders = create_federated_dataloaders(
            train_dataloader.dataset, 5, 0.5, 32, 1, 50  # å°è§„æ¨¡æµ‹è¯•
        )
        print(f"  âœ… è”é‚¦æ•°æ®åˆ’åˆ†æµ‹è¯•æˆåŠŸï¼Œåˆ›å»º{len(client_loaders)}ä¸ªå®¢æˆ·ç«¯")
        
        return True
        
    except Exception as e:
        print(f"  âŒ åŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False

def generate_report(results: Dict[str, Dict[str, bool]]):
    """ç”Ÿæˆæ£€æŸ¥æŠ¥å‘Š"""
    print("\nğŸ“‹ ç”Ÿæˆå®Œæ•´æ€§æ£€æŸ¥æŠ¥å‘Š...")
    
    all_passed = True
    report_lines = []
    
    for category, checks in results.items():
        category_passed = all(checks.values())
        all_passed &= category_passed
        
        status = "âœ… é€šè¿‡" if category_passed else "âŒ å¤±è´¥"
        report_lines.append(f"{category}: {status}")
        
        for item, passed in checks.items():
            item_status = "âœ…" if passed else "âŒ"
            report_lines.append(f"  {item_status} {item}")
    
    # ä¿å­˜æŠ¥å‘Š
    report_content = [
        "# å®éªŒä½“ç³»å®Œæ•´æ€§æ£€æŸ¥æŠ¥å‘Š",
        f"æ£€æŸ¥æ—¶é—´: {__import__('datetime').datetime.now()}",
        "",
        "## æ£€æŸ¥ç»“æœ",
        ""
    ] + report_lines
    
    with open('results/system_check_report.txt', 'w', encoding='utf-8') as f:
        f.write('\n'.join(report_content))
    
    print(f"\nğŸ“Š æ£€æŸ¥æŠ¥å‘Šå·²ä¿å­˜åˆ°: results/system_check_report.txt")
    
    return all_passed

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” è”é‚¦å­¦ä¹  + MergeNet å®éªŒä½“ç³»å®Œæ•´æ€§æ£€æŸ¥")
    print("=" * 50)
    
    # æ£€æŸ¥å„ä¸ªç»„ä»¶
    results = {
        'å®éªŒè„šæœ¬': check_experiment_files(),
        'æ¨¡å‹é…ç½®': check_model_files(),
        'æ•°æ®é›†': check_dataset_files(),
        'Pythonä¾èµ–': check_dependencies(),
        'ç¡¬ä»¶ç¯å¢ƒ': check_hardware()
    }
    
    # åˆ›å»ºç›®å½•
    check_directories()
    
    # åŠŸèƒ½æµ‹è¯•
    test_passed = run_simple_test()
    results['åŠŸèƒ½æµ‹è¯•'] = {'ç®€å•æµ‹è¯•': test_passed}
    
    # ç”ŸæˆæŠ¥å‘Š
    all_passed = generate_report(results)
    
    print("\n" + "=" * 50)
    if all_passed:
        print("ğŸ‰ æ‰€æœ‰æ£€æŸ¥éƒ½é€šè¿‡ï¼å®éªŒä½“ç³»å·²å°±ç»ªã€‚")
        print("\nğŸš€ å¯ä»¥å¼€å§‹è¿è¡Œå®éªŒ:")
        print("  ./run_experiments.sh")
        print("  python auto_experiment_runner.py --run-all")
    else:
        print("âš ï¸ éƒ¨åˆ†æ£€æŸ¥æœªé€šè¿‡ï¼Œè¯·æ ¹æ®ä¸Šè¿°ä¿¡æ¯ä¿®å¤é—®é¢˜ã€‚")
        print("\nğŸ”§ å¸¸è§è§£å†³æ–¹æ¡ˆ:")
        print("  pip install -r requirements_federated.txt")
        print("  python test_environment.py")
    
    return all_passed

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
