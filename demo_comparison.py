"""
å¯¹æ¯”æ¼”ç¤ºï¼šåŸå§‹MergeNet vs è”é‚¦batch-level MergeNet
å±•ç¤ºæ¯fä¸ªbatchæ—¶çš„ä¸åŒå¤„ç†æ–¹å¼
"""
import torch
import torch.nn as nn
import yaml
import numpy as np
from model.MobileNet_v2 import mobilenetv2
from model.ResNet import resnet50
from model.param_attention import ParamAttention
from dataset.cls_dataloader import train_dataloader

def original_mergenet_demo():
    """åŸå§‹MergeNetæ–¹æ³•æ¼”ç¤º"""
    print("ğŸ”¸ åŸå§‹MergeNetæ–¹æ³•:")
    print("   æ¯fä¸ªbatch â†’ ç›´æ¥ä»ResNet50èåˆçŸ¥è¯†åˆ°MobileNetV2")
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # æ¨¡å‹åˆå§‹åŒ–
    mbv2 = mobilenetv2().to(device)
    res = resnet50().to(device)
    
    config = {
        'd_attention': 64, 'h': 8, 'num_layers': 2,
        'a_size_conv': [160, 960], 'a_size_linear': [100, 1280],
        'b_size_linear': [100, 2048], 'mode': 5
    }
    param_attention = ParamAttention(config, mode='a').to(device)
    
    f = 2  # æ¯2ä¸ªbatchèåˆä¸€æ¬¡
    cnt = 0
    
    print(f"   MobileNetV2åˆå§‹å‚æ•°ç¤ºä¾‹: {mbv2.stage6[2].residual[6].weight[0, 0, :3].detach().cpu().numpy()}")
    
    train_iter = iter(train_dataloader)
    for batch_idx in range(5):  # æ¨¡æ‹Ÿ5ä¸ªbatch
        try:
            data, target = next(train_iter)
            data, target = data.to(device), target.to(device)
            
            if cnt % f == 0:
                print(f"   ğŸ“ Batch {cnt}: æ‰§è¡ŒçŸ¥è¯†èåˆ")
                
                # æå–å‚æ•°
                param_a = {
                    'conv': mbv2.stage6[2].residual[6].weight.data.clone().detach().requires_grad_(True).to(device),
                }
                param_b = {
                    'linear_weight': res.fc.weight.data.clone().detach().requires_grad_(True).to(device),
                }
                
                # çŸ¥è¯†èåˆ
                with torch.no_grad():
                    out_a = param_attention(param_a, param_b)
                    
                    # æ›´æ–°MobileNetV2å‚æ•°
                    new_param_mbv = {'stage6.2.residual.6.weight': out_a}
                    mbv2.load_state_dict(new_param_mbv, strict=False)
                
                print(f"   âœ… çŸ¥è¯†èåˆå®Œæˆï¼Œå‚æ•°å·²æ›´æ–°")
                print(f"   MobileNetV2æ›´æ–°åå‚æ•°: {mbv2.stage6[2].residual[6].weight[0, 0, :3].detach().cpu().numpy()}")
            else:
                print(f"   ğŸ“ Batch {cnt}: å¸¸è§„è®­ç»ƒ")
            
            cnt += 1
            
        except StopIteration:
            break

def federated_batch_mergenet_demo():
    """è”é‚¦batch-level MergeNetæ–¹æ³•æ¼”ç¤º"""
    print("\nğŸ”¹ è”é‚¦batch-level MergeNetæ–¹æ³•:")
    print("   æ¯fä¸ªbatch â†’ è”é‚¦å¹³å‡æ‰€æœ‰å®¢æˆ·ç«¯ â†’ ä»ResNet50èåˆçŸ¥è¯† â†’ åˆ†å‘ç»™å®¢æˆ·ç«¯")
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # æ¨¡å‹åˆå§‹åŒ–
    num_clients = 3
    client_models = [mobilenetv2().to(device) for _ in range(num_clients)]
    res = resnet50().to(device)
    
    # ç»™å®¢æˆ·ç«¯æ·»åŠ ä¸€äº›å·®å¼‚æ€§ï¼ˆæ¨¡æ‹Ÿä¸åŒå®¢æˆ·ç«¯çš„è®­ç»ƒçŠ¶æ€ï¼‰
    for i, model in enumerate(client_models):
        with torch.no_grad():
            model.stage6[2].residual[6].weight += torch.randn_like(model.stage6[2].residual[6].weight) * 0.01 * (i + 1)
    
    config = {
        'd_attention': 64, 'h': 8, 'num_layers': 2,
        'a_size_conv': [160, 960], 'a_size_linear': [100, 1280],
        'b_size_linear': [100, 2048], 'mode': 5
    }
    param_attention = ParamAttention(config, mode='a').to(device)
    
    f = 2  # æ¯2ä¸ªbatchè¿›è¡Œè”é‚¦å¹³å‡+èåˆ
    cnt = 0
    
    print(f"   å®¢æˆ·ç«¯åˆå§‹å‚æ•°ç¤ºä¾‹:")
    for i, model in enumerate(client_models):
        print(f"     Client {i}: {model.stage6[2].residual[6].weight[0, 0, :3].detach().cpu().numpy()}")
    
    train_iter = iter(train_dataloader)
    for batch_idx in range(5):  # æ¨¡æ‹Ÿ5ä¸ªbatch
        try:
            data, target = next(train_iter)
            data, target = data.to(device), target.to(device)
            
            if cnt % f == 0:
                print(f"   ğŸ“ Batch {cnt}: æ‰§è¡Œè”é‚¦å¹³å‡ + çŸ¥è¯†èåˆ")
                
                # 1. è”é‚¦å¹³å‡
                print("     ğŸ”„ æ­¥éª¤1: è”é‚¦å¹³å‡å®¢æˆ·ç«¯æ¨¡å‹")
                avg_state_dict = {}
                first_model = client_models[0]
                
                for key in first_model.state_dict().keys():
                    param_type = first_model.state_dict()[key].dtype
                    avg_state_dict[key] = torch.zeros_like(first_model.state_dict()[key], dtype=torch.float32, device=device)
                    
                    for client_model in client_models:
                        avg_state_dict[key] += client_model.state_dict()[key].float()
                    
                    avg_state_dict[key] /= len(client_models)
                    
                    if param_type != torch.float32:
                        avg_state_dict[key] = avg_state_dict[key].to(param_type)
                
                # åˆ›å»ºå¹³å‡æ¨¡å‹
                averaged_model = mobilenetv2().to(device)
                averaged_model.load_state_dict(avg_state_dict)
                
                print(f"     å¹³å‡åå‚æ•°: {averaged_model.stage6[2].residual[6].weight[0, 0, :3].detach().cpu().numpy()}")
                
                # 2. çŸ¥è¯†èåˆ
                print("     ğŸ§  æ­¥éª¤2: MergeNetçŸ¥è¯†èåˆ")
                param_a = {
                    'conv': averaged_model.stage6[2].residual[6].weight.data.clone().detach().requires_grad_(True).to(device),
                }
                param_b = {
                    'linear_weight': res.fc.weight.data.clone().detach().requires_grad_(True).to(device),
                }
                
                with torch.no_grad():
                    out_a = param_attention(param_a, param_b)
                    new_param_dict = {'stage6.2.residual.6.weight': out_a}
                    averaged_model.load_state_dict(new_param_dict, strict=False)
                
                print(f"     èåˆåå‚æ•°: {averaged_model.stage6[2].residual[6].weight[0, 0, :3].detach().cpu().numpy()}")
                
                # 3. åˆ†å‘ç»™å®¢æˆ·ç«¯
                print("     ğŸ“¤ æ­¥éª¤3: åˆ†å‘èåˆåå‚æ•°ç»™æ‰€æœ‰å®¢æˆ·ç«¯")
                fused_state_dict = averaged_model.state_dict()
                for i, client_model in enumerate(client_models):
                    client_model.load_state_dict(fused_state_dict)
                    print(f"       Client {i} æ›´æ–°å: {client_model.stage6[2].residual[6].weight[0, 0, :3].detach().cpu().numpy()}")
                
                print("   âœ… è”é‚¦å¹³å‡ + çŸ¥è¯†èåˆå®Œæˆ")
            else:
                print(f"   ğŸ“ Batch {cnt}: å®¢æˆ·ç«¯æœ¬åœ°è®­ç»ƒ")
                # æ¨¡æ‹Ÿæœ¬åœ°è®­ç»ƒå¯¼è‡´çš„å‚æ•°å·®å¼‚
                for model in client_models:
                    with torch.no_grad():
                        model.stage6[2].residual[6].weight += torch.randn_like(model.stage6[2].residual[6].weight) * 0.005
            
            cnt += 1
            
        except StopIteration:
            break

def main():
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    print("=" * 60)
    print("ğŸ“Š åŸå§‹MergeNet vs è”é‚¦batch-level MergeNet å¯¹æ¯”æ¼”ç¤º")
    print("=" * 60)
    
    # åŸå§‹æ–¹æ³•æ¼”ç¤º
    original_mergenet_demo()
    
    # è”é‚¦æ–¹æ³•æ¼”ç¤º
    federated_batch_mergenet_demo()
    
    print("\n" + "=" * 60)
    print("ğŸ“ˆ å…³é”®å·®å¼‚æ€»ç»“:")
    print("=" * 60)
    print("ğŸ”¸ åŸå§‹æ–¹æ³•:")
    print("   - å•ä¸€MobileNetV2æ¨¡å‹")
    print("   - æ¯fä¸ªbatchç›´æ¥èåˆçŸ¥è¯†")
    print("   - ç®€å•ç›´æ¥ï¼Œä½†ç¼ºä¹åˆ†å¸ƒå¼ä¼˜åŠ¿")
    
    print("\nğŸ”¹ è”é‚¦batch-levelæ–¹æ³•:")
    print("   - å¤šä¸ªå®¢æˆ·ç«¯MobileNetV2æ¨¡å‹")
    print("   - æ¯fä¸ªbatchå…ˆè”é‚¦å¹³å‡ï¼Œå†èåˆçŸ¥è¯†ï¼Œæœ€ååˆ†å‘")
    print("   - ç»“åˆäº†è”é‚¦å­¦ä¹ çš„åˆ†å¸ƒå¼ä¼˜åŠ¿å’ŒMergeNetçš„çŸ¥è¯†èåˆ")
    print("   - å¯èƒ½è·å¾—æ›´å¥½çš„æ³›åŒ–èƒ½åŠ›å’Œé²æ£’æ€§")
    
    print(f"\nğŸš€ è¦è¿è¡Œå®Œæ•´å¯¹æ¯”å®éªŒ:")
    print(f"   åŸå§‹æ–¹æ³•: python run_res50_mbv2.py")
    print(f"   è”é‚¦æ–¹æ³•: python federated_batch_mergenet.py")

if __name__ == "__main__":
    main()
