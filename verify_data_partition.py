"""
éªŒè¯è”é‚¦å­¦ä¹ æ•°æ®åˆ’åˆ†æ˜¯å¦æ­£ç¡®å·¥ä½œ
ç¡®è®¤æ¯ä¸ªå®¢æˆ·ç«¯ä½¿ç”¨ä¸åŒçš„æ•°æ®å­é›†
"""
import torch
import numpy as np
from collections import defaultdict
from dataset.cls_dataloader import train_dataloader
from dataset.federated_data_partition import create_federated_dataloaders

def verify_data_partition():
    """éªŒè¯æ•°æ®åˆ’åˆ†çš„æ­£ç¡®æ€§"""
    print("ğŸ” éªŒè¯è”é‚¦å­¦ä¹ æ•°æ®åˆ’åˆ†")
    print("=" * 50)
    
    # åˆ›å»ºè”é‚¦æ•°æ®åˆ’åˆ†
    partitioner, client_dataloaders = create_federated_dataloaders(
        dataset=train_dataloader.dataset,
        num_clients=10,  # ä¸ºäº†å¿«é€ŸéªŒè¯ï¼Œä½¿ç”¨10ä¸ªå®¢æˆ·ç«¯
        alpha=0.5,
        batch_size=32,
        num_workers=0,  # é¿å…å¤šè¿›ç¨‹é—®é¢˜
        min_samples_per_client=50
    )
    
    print(f"âœ… åˆ›å»ºäº†{len(client_dataloaders)}ä¸ªå®¢æˆ·ç«¯æ•°æ®åŠ è½½å™¨")
    
    # 1. éªŒè¯æ•°æ®ä¸é‡å¤
    print("\nğŸ“Š éªŒè¯æ•°æ®ä¸é‡å¤...")
    all_indices = set()
    client_indices = []
    
    for client_id in range(len(client_dataloaders)):
        client_dataset = partitioner.get_client_dataset(client_id)
        indices = set(client_dataset.indices)
        client_indices.append(indices)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰é‡å¤
        overlap = all_indices.intersection(indices)
        if overlap:
            print(f"âŒ å®¢æˆ·ç«¯{client_id}ä¸å…¶ä»–å®¢æˆ·ç«¯æœ‰é‡å¤æ•°æ®: {len(overlap)}ä¸ªæ ·æœ¬")
        else:
            print(f"âœ… å®¢æˆ·ç«¯{client_id}: {len(indices)}ä¸ªç‹¬ç‰¹æ ·æœ¬")
        
        all_indices.update(indices)
    
    print(f"âœ… æ€»å…±ä½¿ç”¨çš„æ ·æœ¬æ•°: {len(all_indices)}")
    print(f"âœ… åŸå§‹æ•°æ®é›†æ ·æœ¬æ•°: {len(train_dataloader.dataset)}")
    
    # 2. éªŒè¯æ ‡ç­¾åˆ†å¸ƒ
    print("\nğŸ·ï¸ éªŒè¯æ ‡ç­¾åˆ†å¸ƒ...")
    for client_id in range(min(5, len(client_dataloaders))):  # åªæ£€æŸ¥å‰5ä¸ªå®¢æˆ·ç«¯
        client_labels = []
        dataloader = client_dataloaders[client_id]
        
        for batch_idx, (data, labels) in enumerate(dataloader):
            client_labels.extend(labels.tolist())
            if batch_idx >= 5:  # åªæ£€æŸ¥å‰å‡ ä¸ªbatch
                break
        
        if client_labels:
            unique_labels = set(client_labels)
            label_counts = defaultdict(int)
            for label in client_labels:
                label_counts[label] += 1
            
            print(f"âœ… å®¢æˆ·ç«¯{client_id}: {len(unique_labels)}ä¸ªä¸åŒç±»åˆ«ï¼Œå‰5ä¸ªç±»åˆ«åˆ†å¸ƒ: {dict(list(label_counts.items())[:5])}")
    
    # 3. éªŒè¯æ•°æ®åŠ è½½
    print("\nğŸ“¥ éªŒè¯æ•°æ®åŠ è½½...")
    for client_id in range(min(3, len(client_dataloaders))):
        dataloader = client_dataloaders[client_id]
        try:
            data_iter = iter(dataloader)
            batch1 = next(data_iter)
            batch2 = next(data_iter)
            
            print(f"âœ… å®¢æˆ·ç«¯{client_id}: æˆåŠŸåŠ è½½æ‰¹æ¬¡ï¼Œæ•°æ®å½¢çŠ¶: {batch1[0].shape}, æ ‡ç­¾å½¢çŠ¶: {batch1[1].shape}")
            
            # éªŒè¯ä¸¤ä¸ªæ‰¹æ¬¡çš„æ•°æ®ä¸åŒ
            if not torch.equal(batch1[0], batch2[0]):
                print(f"âœ… å®¢æˆ·ç«¯{client_id}: æ‰¹æ¬¡é—´æ•°æ®ä¸åŒï¼ˆæ­£ç¡®ï¼‰")
            else:
                print(f"âŒ å®¢æˆ·ç«¯{client_id}: æ‰¹æ¬¡é—´æ•°æ®ç›¸åŒï¼ˆé”™è¯¯ï¼‰")
                
        except Exception as e:
            print(f"âŒ å®¢æˆ·ç«¯{client_id}: æ•°æ®åŠ è½½å¤±è´¥ - {e}")
    
    # 4. éªŒè¯å®¢æˆ·ç«¯é—´æ•°æ®ä¸åŒ
    print("\nğŸ”„ éªŒè¯å®¢æˆ·ç«¯é—´æ•°æ®å·®å¼‚...")
    if len(client_dataloaders) >= 2:
        # æ¯”è¾ƒå‰ä¸¤ä¸ªå®¢æˆ·ç«¯çš„ç¬¬ä¸€ä¸ªbatch
        try:
            batch_client0 = next(iter(client_dataloaders[0]))
            batch_client1 = next(iter(client_dataloaders[1]))
            
            if not torch.equal(batch_client0[0], batch_client1[0]):
                print("âœ… ä¸åŒå®¢æˆ·ç«¯ä½¿ç”¨ä¸åŒæ•°æ®ï¼ˆæ­£ç¡®ï¼‰")
            else:
                print("âŒ ä¸åŒå®¢æˆ·ç«¯ä½¿ç”¨ç›¸åŒæ•°æ®ï¼ˆé”™è¯¯ï¼‰")
                
            # æ£€æŸ¥æ ‡ç­¾åˆ†å¸ƒå·®å¼‚
            labels0 = batch_client0[1].tolist()
            labels1 = batch_client1[1].tolist()
            
            unique0 = set(labels0)
            unique1 = set(labels1)
            
            print(f"âœ… å®¢æˆ·ç«¯0æ ‡ç­¾: {sorted(list(unique0))[:10]}...")
            print(f"âœ… å®¢æˆ·ç«¯1æ ‡ç­¾: {sorted(list(unique1))[:10]}...")
            
            if unique0 != unique1:
                print("âœ… ä¸åŒå®¢æˆ·ç«¯æœ‰ä¸åŒçš„æ ‡ç­¾åˆ†å¸ƒï¼ˆç¬¦åˆNon-IIDï¼‰")
            
        except Exception as e:
            print(f"âŒ å®¢æˆ·ç«¯é—´æ¯”è¾ƒå¤±è´¥: {e}")
    
    return True

def verify_training_flow():
    """éªŒè¯è®­ç»ƒæµç¨‹ä¸­çš„æ•°æ®ä½¿ç”¨"""
    print("\nğŸ”„ éªŒè¯è®­ç»ƒæµç¨‹ä¸­çš„æ•°æ®ä½¿ç”¨")
    print("=" * 50)
    
    # åˆ›å»ºè”é‚¦æ•°æ®åˆ’åˆ†
    partitioner, client_dataloaders = create_federated_dataloaders(
        dataset=train_dataloader.dataset,
        num_clients=5,
        alpha=0.5,
        batch_size=32,
        num_workers=0,
        min_samples_per_client=50
    )
    
    # æ¨¡æ‹Ÿè®­ç»ƒæµç¨‹
    selected_client_ids = [0, 2, 4]  # é€‰æ‹©3ä¸ªå®¢æˆ·ç«¯
    print(f"é€‰æ‹©å®¢æˆ·ç«¯: {selected_client_ids}")
    
    # åˆ›å»ºé€‰ä¸­å®¢æˆ·ç«¯çš„æ•°æ®è¿­ä»£å™¨
    selected_client_iterators = []
    for client_id in selected_client_ids:
        iterator = iter(client_dataloaders[client_id])
        selected_client_iterators.append(iterator)
    
    print(f"âœ… åˆ›å»ºäº†{len(selected_client_iterators)}ä¸ªå®¢æˆ·ç«¯æ•°æ®è¿­ä»£å™¨")
    
    # æ¨¡æ‹Ÿå‡ ä¸ªbatchçš„è®­ç»ƒ
    for batch_idx in range(3):
        print(f"\n--- Batch {batch_idx} ---")
        
        # ResNetä½¿ç”¨å®Œæ•´æ•°æ®
        try:
            if batch_idx == 0:
                train_iter = iter(train_dataloader)
            img_res, label_res = next(train_iter)
            print(f"âœ… ResNetæ•°æ®: {img_res.shape}, æ ‡ç­¾èŒƒå›´: {label_res.min().item()}-{label_res.max().item()}")
        except StopIteration:
            train_iter = iter(train_dataloader)
            img_res, label_res = next(train_iter)
            print(f"âœ… ResNetæ•°æ®ï¼ˆé‡æ–°å¼€å§‹ï¼‰: {img_res.shape}")
        
        # å„å®¢æˆ·ç«¯ä½¿ç”¨è‡ªå·±çš„æ•°æ®
        active_clients = 0
        for i, (client_id, client_iterator) in enumerate(zip(selected_client_ids, selected_client_iterators)):
            try:
                img_client, label_client = next(client_iterator)
                print(f"âœ… å®¢æˆ·ç«¯{client_id}æ•°æ®: {img_client.shape}, æ ‡ç­¾èŒƒå›´: {label_client.min().item()}-{label_client.max().item()}")
                active_clients += 1
                
                # éªŒè¯å®¢æˆ·ç«¯æ•°æ®ä¸ResNetæ•°æ®ä¸åŒ
                if not torch.equal(img_client, img_res):
                    print(f"âœ… å®¢æˆ·ç«¯{client_id}ä¸ResNetæ•°æ®ä¸åŒï¼ˆæ­£ç¡®ï¼‰")
                else:
                    print(f"âŒ å®¢æˆ·ç«¯{client_id}ä¸ResNetæ•°æ®ç›¸åŒï¼ˆé”™è¯¯ï¼‰")
                    
            except StopIteration:
                print(f"âš ï¸ å®¢æˆ·ç«¯{client_id}æ•°æ®ç”¨å®Œ")
        
        print(f"æ´»è·ƒå®¢æˆ·ç«¯æ•°: {active_clients}")
    
    return True

def main():
    """ä¸»éªŒè¯å‡½æ•°"""
    print("ğŸš€ è”é‚¦å­¦ä¹ æ•°æ®åˆ’åˆ†éªŒè¯")
    print("=" * 60)
    
    try:
        # éªŒè¯æ•°æ®åˆ’åˆ†
        verify_data_partition()
        
        # éªŒè¯è®­ç»ƒæµç¨‹
        verify_training_flow()
        
        print("\n" + "=" * 60)
        print("âœ… æ‰€æœ‰éªŒè¯é€šè¿‡ï¼æ•°æ®åˆ’åˆ†æ­£ç¡®å·¥ä½œ")
        print("ğŸ“‹ éªŒè¯ç»“æœ:")
        print("   âœ… æ¯ä¸ªå®¢æˆ·ç«¯ä½¿ç”¨ä¸åŒçš„æ•°æ®å­é›†")
        print("   âœ… å®¢æˆ·ç«¯é—´æ— æ•°æ®é‡å¤")
        print("   âœ… æ ‡ç­¾åˆ†å¸ƒå‘ˆç°Non-IIDç‰¹æ€§")
        print("   âœ… æ•°æ®åŠ è½½å™¨æ­£å¸¸å·¥ä½œ")
        print("   âœ… è®­ç»ƒæµç¨‹ä¸­æ•°æ®ä½¿ç”¨æ­£ç¡®")
        
    except Exception as e:
        print(f"\nâŒ éªŒè¯è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
