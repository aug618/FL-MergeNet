"""
æµ‹è¯•50ä¸ªå®¢æˆ·ç«¯è”é‚¦å­¦ä¹ +MergeNetçš„åŸºæœ¬åŠŸèƒ½
"""
import torch
import yaml
from model.MobileNet_v2 import mobilenetv2
from model.ResNet import resnet50
from model.param_attention import ParamAttention
from dataset.cls_dataloader import train_dataloader
from dataset.federated_data_partition import create_federated_dataloaders, select_random_clients

def test_federated_data_partition():
    """æµ‹è¯•è”é‚¦æ•°æ®åˆ’åˆ†åŠŸèƒ½"""
    print("=== æµ‹è¯•è”é‚¦æ•°æ®åˆ’åˆ† ===")
    
    # åˆ›å»ºè”é‚¦æ•°æ®åˆ’åˆ†
    partitioner, client_dataloaders = create_federated_dataloaders(
        dataset=train_dataloader.dataset,
        num_clients=50,
        alpha=0.5,
        batch_size=32,
        num_workers=2,
        min_samples_per_client=50
    )
    
    # æ£€æŸ¥æ•°æ®åˆ’åˆ†
    stats = partitioner.get_data_distribution()
    print(f"âœ… åˆ›å»ºäº†{len(client_dataloaders)}ä¸ªå®¢æˆ·ç«¯æ•°æ®åŠ è½½å™¨")
    print(f"âœ… å®¢æˆ·ç«¯æ ·æœ¬æ•°èŒƒå›´: {min(stats['client_sizes'])} - {max(stats['client_sizes'])}")
    
    # æµ‹è¯•éšæœºé€‰æ‹©å®¢æˆ·ç«¯
    selected = select_random_clients(50, 15, seed=42)
    print(f"âœ… éšæœºé€‰æ‹©15ä¸ªå®¢æˆ·ç«¯: {selected[:5]}...ç­‰")
    
    # æµ‹è¯•æ•°æ®åŠ è½½
    first_client_loader = client_dataloaders[0]
    for batch_idx, (data, target) in enumerate(first_client_loader):
        if batch_idx == 0:
            print(f"âœ… ç¬¬ä¸€ä¸ªå®¢æˆ·ç«¯æ•°æ®å½¢çŠ¶: {data.shape}, æ ‡ç­¾å½¢çŠ¶: {target.shape}")
            break
    
    return True

def test_model_creation():
    """æµ‹è¯•50ä¸ªå®¢æˆ·ç«¯æ¨¡å‹åˆ›å»º"""
    print("\n=== æµ‹è¯•æ¨¡å‹åˆ›å»º ===")
    
    # åˆ›å»º50ä¸ªå®¢æˆ·ç«¯æ¨¡å‹
    num_clients = 50
    client_models = [mobilenetv2() for _ in range(num_clients)]
    res_model = resnet50()
    
    print(f"âœ… åˆ›å»ºäº†{len(client_models)}ä¸ªMobileNetV2å®¢æˆ·ç«¯æ¨¡å‹")
    print(f"âœ… ResNet50æ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in res_model.parameters()):,}")
    
    # æµ‹è¯•æ¨¡å‹å‰å‘ä¼ æ’­
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # ç§»åŠ¨ç¬¬ä¸€ä¸ªå®¢æˆ·ç«¯æ¨¡å‹åˆ°è®¾å¤‡
    client_models[0].to(device)
    res_model.to(device)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    test_input = torch.randn(2, 3, 32, 32).to(device)
    
    with torch.no_grad():
        client_output = client_models[0](test_input)
        res_output = res_model(test_input)
    
    print(f"âœ… å®¢æˆ·ç«¯æ¨¡å‹è¾“å‡ºå½¢çŠ¶: {client_output.shape}")
    print(f"âœ… ResNetæ¨¡å‹è¾“å‡ºå½¢çŠ¶: {res_output.shape}")
    
    return True

def test_param_attention():
    """æµ‹è¯•å‚æ•°æ³¨æ„åŠ›æ¨¡å—"""
    print("\n=== æµ‹è¯•å‚æ•°æ³¨æ„åŠ›æ¨¡å— ===")
    
    # åŠ è½½é…ç½®
    config = {
        'd_attention': 64,
        'h': 8,
        'num_layers': 2,
        'a_size_conv': [160, 960],
        'a_size_linear': [100, 1280],
        'b_size_linear': [100, 2048],
        'mode': 5
    }
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # åˆ›å»ºæ¨¡å‹
    mbv2 = mobilenetv2().to(device)
    res = resnet50().to(device)
    param_attention = ParamAttention(config, mode='a').to(device)
    
    # æå–å‚æ•°
    param_a = {
        'conv': mbv2.stage6[2].residual[6].weight.data.clone().detach().requires_grad_(True).to(device),
    }
    param_b = {
        'linear_weight': res.fc.weight.data.clone().detach().requires_grad_(True).to(device),
    }
    
    print(f"âœ… è¾“å…¥å‚æ•°Aå½¢çŠ¶: {param_a['conv'].shape}")
    print(f"âœ… è¾“å…¥å‚æ•°Bå½¢çŠ¶: {param_b['linear_weight'].shape}")
    
    # æµ‹è¯•å‚æ•°æ³¨æ„åŠ›
    try:
        out_a = param_attention(param_a, param_b)
        print(f"âœ… å‚æ•°æ³¨æ„åŠ›è¾“å‡ºå½¢çŠ¶: {out_a.shape}")
        print(f"âœ… è¾“å‡ºä¸è¾“å…¥Aå½¢çŠ¶åŒ¹é…: {out_a.shape == param_a['conv'].shape}")
        return True
    except Exception as e:
        print(f"âŒ å‚æ•°æ³¨æ„åŠ›æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_federated_averaging():
    """æµ‹è¯•è”é‚¦å¹³å‡åŠŸèƒ½"""
    print("\n=== æµ‹è¯•è”é‚¦å¹³å‡ ===")
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # åˆ›å»º3ä¸ªæµ‹è¯•å®¢æˆ·ç«¯æ¨¡å‹
    client_models = [mobilenetv2().to(device) for _ in range(3)]
    
    # ç»™æ¨¡å‹æ·»åŠ ä¸€äº›å·®å¼‚
    for i, model in enumerate(client_models):
        with torch.no_grad():
            for param in model.parameters():
                param.add_(torch.randn_like(param) * 0.01 * (i + 1))
    
    # æµ‹è¯•è”é‚¦å¹³å‡
    from federated_batch_mergenet import federated_average_models
    
    avg_state_dict = federated_average_models(client_models, device)
    
    if avg_state_dict is not None:
        print(f"âœ… è”é‚¦å¹³å‡æˆåŠŸï¼ŒåŒ…å«{len(avg_state_dict)}ä¸ªå‚æ•°å±‚")
        
        # åˆ›å»ºå¹³å‡æ¨¡å‹å¹¶åŠ è½½å‚æ•°
        avg_model = mobilenetv2().to(device)
        avg_model.load_state_dict(avg_state_dict)
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        test_input = torch.randn(2, 3, 32, 32).to(device)
        with torch.no_grad():
            output = avg_model(test_input)
        print(f"âœ… å¹³å‡æ¨¡å‹å‰å‘ä¼ æ’­æˆåŠŸï¼Œè¾“å‡ºå½¢çŠ¶: {output.shape}")
        return True
    else:
        print("âŒ è”é‚¦å¹³å‡å¤±è´¥")
        return False

def test_configuration():
    """æµ‹è¯•é…ç½®æ–‡ä»¶åŠ è½½"""
    print("\n=== æµ‹è¯•é…ç½®æ–‡ä»¶ ===")
    
    try:
        config = yaml.load(open('config/param_attention_config.yaml', 'r'), Loader=yaml.Loader)
        print(f"âœ… é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ")
        print(f"âœ… é…ç½®å‚æ•°: {list(config.keys())}")
        return True
    except Exception as e:
        print(f"âŒ é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
        return False

def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("ğŸš€ 50ä¸ªå®¢æˆ·ç«¯è”é‚¦å­¦ä¹ +MergeNet åŠŸèƒ½æµ‹è¯•")
    print("=" * 60)
    
    tests = [
        ("é…ç½®æ–‡ä»¶", test_configuration),
        ("è”é‚¦æ•°æ®åˆ’åˆ†", test_federated_data_partition),
        ("æ¨¡å‹åˆ›å»º", test_model_creation),
        ("å‚æ•°æ³¨æ„åŠ›", test_param_attention),
        ("è”é‚¦å¹³å‡", test_federated_averaging),
    ]
    
    results = []
    for test_name, test_func in tests:
        try:
            result = test_func()
            results.append((test_name, result))
        except Exception as e:
            print(f"âŒ {test_name}æµ‹è¯•å‡ºé”™: {e}")
            results.append((test_name, False))
    
    # æ€»ç»“
    print("\n" + "=" * 60)
    print("ğŸ” æµ‹è¯•æ€»ç»“:")
    
    passed = 0
    total = len(results)
    
    for test_name, result in results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"  {test_name}: {status}")
        if result:
            passed += 1
    
    print(f"\nğŸ“Š æ€»ä½“ç»“æœ: {passed}/{total} æµ‹è¯•é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç³»ç»Ÿå·²å‡†å¤‡å¥½è¿è¡Œ50ä¸ªå®¢æˆ·ç«¯çš„è”é‚¦å­¦ä¹ å®éªŒ")
        print(f"\nğŸš€ è¿è¡Œå®Œæ•´å®éªŒ:")
        print(f"   python federated_batch_mergenet.py")
    else:
        print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç³»ç»Ÿé…ç½®")
        
    return passed == total

if __name__ == "__main__":
    main()
